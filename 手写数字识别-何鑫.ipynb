{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1导包\n",
    "import tets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#2 定义超参\n",
    "BATCH_SIZE = 8 #每次处理的数据数量\n",
    "DEVICE = torch.device(\"cpu\")#模型是在CPU还是GPU训练\n",
    "EPOCHS = 3   #训练的轮次\n",
    "\n",
    "#3 构建pipeline，对图像处理进行旋转等处理\n",
    "pipeline = transforms.Compose([\n",
    "    transforms.ToTensor(),#将图片转换成tensor格式\n",
    "    transforms.Normalize((0.1307),(0.3081,))#正则化，出现过拟合，降低模型复杂度\n",
    "])\n",
    "\n",
    "#4 下载、加载数据集\n",
    "from torch.utils.data import DataLoader\n",
    "#下载数据集\n",
    "train_set = datasets.MNIST(\"data\", train=True, download=True, transform=pipeline)\n",
    "test_set = datasets.MNIST(\"data\", train=False,download=True, transform=pipeline)\n",
    "#加载数据集\n",
    "train_loder = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)#将图片顺序打乱\n",
    "test_loder = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)#将图片顺序打乱\n",
    "\n",
    "# 显示图片\n",
    "# with open(\"data/MNIST/raw/train-images-idx3-ubyte\", \"rb\") as f:\n",
    "#     file = f.read()\n",
    "# image1 = [int(str(item).encode('ascii'), 16) for item in file[16:16+784]]\n",
    "# # print(image1)\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# image1_np = np.array(image1, dtype=np.uint8).reshape(28, 28, 1)\n",
    "# print(image1_np.shape)\n",
    "# cv2.imwrite(\"1.jpg\", image1_np)\n",
    "\n",
    "# 5构建网络模型\n",
    "class Digit(nn.Module):\n",
    "    #模型初始化\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5) #1:灰度图片的通道，10：输出通道，5：卷积核数量\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3)#10:输入通道，20：输出通道，3：卷积核数量\n",
    "        self.fc1 = nn.Linear(20*10*10, 500) #20*20*10:输入通道，500：输出通道\n",
    "        self.fc2 = nn.Linear(500, 10)#500:输入通道，10：输出通道\n",
    "\n",
    "    #正向传播\n",
    "    def forward(self, x):\n",
    "        input_size = x.size(0) #batch_size\n",
    "        x = self.conv1(x)#输入：batch__size*1*28*28,输出：batch_size*10*24*24（卷积计算：28-5+1）\n",
    "        x = F.relu(x)#激活函数\n",
    "        x = F.max_pool2d(x, 2, 2)#池化层（降采样）输入：batch_size*10*24*24 输出：batch_size*10*12*12\n",
    "\n",
    "        x = self.conv2(x)#输入batch_size*10*12*12 输出：batch_size*20*10*10(12-3+1)\n",
    "        x = F.relu(x)#激活函数\n",
    "\n",
    "        x = x.view(input_size, -1) #将二维图像矩阵转化成一维向量   -1：自动计算维度20*10*10=2000\n",
    "\n",
    "        x = self.fc1(x) #输入：batch_size*2000 输出：batch_size*500\n",
    "        x = F.relu(x)#激活函数\n",
    "\n",
    "        x = self.fc2(x)#输入：batch_size*500 输出：batch_size*10\n",
    "\n",
    "        output = F.log_softmax(x, dim=1) #计算分类后，每个数字的概率值\n",
    "        return output\n",
    "\n",
    "\n",
    "#6 定义优化器\n",
    "model = Digit().to(DEVICE)#选择设备\n",
    "optimizer = optim.Adam(model.parameters())#选择优化方法\n",
    "\n",
    "#7 定义训练方法\n",
    "def train_model(model, devide, train_loader, optimizer, epoch):\n",
    "    #模型训练\n",
    "    model.train()\n",
    "    for batch_index, data, target in tets.datas_0:\n",
    "        print(train_loader)\n",
    "        print(type(target[0]))\n",
    "        print(data[0])\n",
    "\n",
    "        print(batch_index)\n",
    "        #将数据部署到模型\n",
    "        data, target = data.to(devide), target.to(devide)\n",
    "        #梯度初始化为0\n",
    "        optimizer.zero_grad()\n",
    "        #训练后的结果\n",
    "        output = model(data)\n",
    "        #计算损失\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        # #找到概率值最大的下标\n",
    "        # pred = output.max(1, keepdim=True)#pred = output.argmax(dim=1)\n",
    "        #反向传播\n",
    "        loss.backward()\n",
    "        #参数优化\n",
    "        optimizer.step()\n",
    "        if batch_index % 3000 == 0:\n",
    "            print('Train Epoch : {} \\t Loss : {:.6f}'.format(epoch, loss.item()))\n",
    "\n",
    "# 8测试方法\n",
    "def test_model(model, devide, test_loader):\n",
    "    #模型验证\n",
    "    model.eval()\n",
    "    #正确率\n",
    "    correct =0.0\n",
    "    #测试损失\n",
    "    test_loss = 0.0\n",
    "    #进行测试\n",
    "    with torch.no_grad(): #不会计算梯度，也不会反向传播\n",
    "        for data, target in test_loader:\n",
    "            #部署到device上\n",
    "            data, target = data.to(devide), target.to(devide)\n",
    "            #测试数据\n",
    "            output = model(data)\n",
    "            #计算测试损失\n",
    "            test_loss += F.cross_entropy(output, target).item()\n",
    "            #找到概率值最大的下标\n",
    "            pred = output.argmax(dim=1)\n",
    "            # pred = output.max(1, keepdim=True)[0/1] \"0\":概率值 \"1\"：图片索引\n",
    "            #\n",
    "            # ？？？model.softmax()\n",
    "            #累计正确率\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loder.dataset)\n",
    "        print(\"Test —— Average loss : {:.4f}, Accuracy : {:.3f}\\n\".format(\n",
    "            test_loss, 100.0 * correct / len(test_loader.dataset)))\n",
    "\n",
    "#9 调用 7/8方法\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_model(model, DEVICE, train_loder, optimizer, epoch)\n",
    "    test_model(model, DEVICE, test_loder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
