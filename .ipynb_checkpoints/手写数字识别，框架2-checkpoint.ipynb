{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as tud\n",
    "import numpy as np\n",
    "import torch\n",
    "import pdb\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import struct\n",
    "import gzip\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "def load_data_image():\n",
    "    #读取文件\n",
    "    binfile = open('../data/train-images.idx3-ubyte', 'rb')\n",
    "    buffers = binfile.read()\n",
    "    #/读取前四个无符号整数\n",
    "    magic, num, cows, cols = struct.unpack_from('>IIII',buffers,0)\n",
    "    #获得偏移\n",
    "    offset = struct.calcsize('>IIII')\n",
    "    #计算所读取的数据大小num*cows*cols个bit，>表示大端读取\n",
    "    strString = '>' + str(num*cows*cols) + 'B'\n",
    "    #读取图片数据并转化矩阵\n",
    "    training_image = struct.unpack_from(strString, buffers, offset)\n",
    "    training_image = np.reshape(training_image,(num,cows*cols))\n",
    "    binfile.close()\n",
    "    return (training_image)\n",
    "def load_data_lable():\n",
    "    #读取文件\n",
    "    binfile = open('../data/train-labels.idx1-ubyte', 'rb')\n",
    "    buffers = binfile.read()\n",
    "    #/读取前两个无符号整数\n",
    "    magic, num = struct.unpack_from('>II',buffers,0)\n",
    "    #获得偏移\n",
    "    offset = struct.calcsize('>II')\n",
    "    #计算所读取的数据大小num*cows*cols个bit，>表示大端读取\n",
    "    strString = '>' + str(num) + 'B'\n",
    "    #读取图片数据并转化矩阵\n",
    "    training_lable = struct.unpack_from(strString, buffers, offset)\n",
    "    training_lable = np.reshape(training_lable,(num))\n",
    "    binfile.close()\n",
    "    return (training_lable)\n",
    "training_image = torch.from_numpy(load_data_image()).to(DEVICE)\n",
    "training_lable = torch.from_numpy(load_data_lable()).to(DEVICE)\n",
    "training_image = training_image.float()\n",
    "rtaining_lable = training_lable.long()\n",
    "\n",
    "\n",
    "    \n",
    "for x,i in zip(training_image,range(len(training_image))):   #对大数值数据的处理，此方法可以大幅加快训练速度\n",
    "    training_image[i] = torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 784])\n",
      "torch.Size([10000])\n",
      "10000\n",
      "tensor(4, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(training_image.shape)\n",
    "print(training_lable.shape)\n",
    "print(len(training_image))\n",
    "print(training_lable[2])\n",
    "# print(training_image[2])\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandWrittenDataset(tud.Dataset): #定义数据读取类，此类用于读取数据，最为关键的函数是getitem（）\n",
    "    def __init__(self,training_image,training_lable): #此函数用于初始化\n",
    "        super(HandWrittenDataset, self).__init__()\n",
    "        self.training_data = training_image\n",
    "        self.training_lable = training_lable\n",
    "        \n",
    "    def __len__(self): #此函数用于确定总数据大小，用于生成所有的bitch\n",
    "        return len(self.training_data)\n",
    "    def __getitem__(self, idx): #此函数会根据len()函数获得的总大小来生成一个个bitch数据，返回值就是每一个bitch里面所装的东西。\n",
    "        \n",
    "        return self.training_data[idx],self.training_lable[idx];\n",
    "#此类的具体用下在下一运行格中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此块儿说明了dataloader的工作方式，以及使用方法\n",
    "dataset = HandWrittenDataset(training_image,training_lable)#调用数据读取类\n",
    "dataloader = tud.DataLoader(dataset, batch_size=10, shuffle=True)#取出以bitch为单位的数据，shuffle参数代表是否随机打乱\n",
    "#这就取出了所有的数据，并以bitch为单位打包起来\n",
    "\n",
    "#接下来介绍如何用取样（sampler）的方法方便的把数据分成测试集和数据集\n",
    "dataset = HandWrittenDataset(training_image,training_lable)#调用数据读取类\n",
    "n_train = len(training_image)\n",
    "split = n_train // 9   #整数除法，要把数据分成9:1的训练集和测试集\n",
    "indices = list(range(n_train))\n",
    "train_sampler = tud.sampler.SubsetRandomSampler(indices[split:])  \n",
    "test_sampler = tud.sampler.SubsetRandomSampler(indices[:split])\n",
    "train_loader = tud.DataLoader(dataset, sampler=train_sampler,batch_size = 5, shuffle=False)#利用采样的方法进行提取\n",
    "test_loader = tud.DataLoader(dataset, sampler=test_sampler, batch_size = 5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 784])\n"
     ]
    }
   ],
   "source": [
    "print(training_image.shape)\n",
    "# sum(y[int(x)] == 1 for x, y in zip(xxx,self.test_lables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (data, lable) in enumerate(dataloader):\n",
    "#     if i >= 1:\n",
    "#         break\n",
    "#     print(data, lable)\n",
    "# for i, (data, lable) in enumerate(train_loader):\n",
    "#     print(i)\n",
    "# for i, (data, lable) in enumerate(test_loader):\n",
    "#     print(i)\n",
    "#     print(data, lable)\n",
    "NUM_EPOCHS = 30\n",
    "# for i in range(10):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandWrittenDataset(tud.Dataset): #定义数据读取类，此类用于读取数据，最为关键的函数是getitem（）\n",
    "    def __init__(self,training_image,training_lable, CEL): #此函数用于初始化\n",
    "        super(HandWrittenDataset, self).__init__()\n",
    "        self.training_data = training_image\n",
    "        if(CEL == True): #CEL 代表CrossEntropyLoss 此loss方程需要需要的结果y和其他loss方程不一样（单维），所以需要另外处理\n",
    "            self.training_lable = training_lable\n",
    "        else:\n",
    "            self.training_lable = torch.zeros(len(training_image),10,device = DEVICE)\n",
    "            for i in range(len(training_image)):\n",
    "                self.training_lable[i][training_lable[i]] = 1\n",
    "        \n",
    "    def __len__(self): #此函数用于确定总数据大小，用于生成所有的bitch\n",
    "        return len(self.training_data)\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.training_data[idx],self.training_lable[idx];\n",
    "            \n",
    "        \n",
    "#此类的具体用下在下一运行格中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module): #定义网络类，此类用于设定所使用的网络。\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(784,100)\n",
    "        self.linear2 = torch.nn.Linear(100,50)\n",
    "        self.linear3 = torch.nn.Linear(50,10)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = torch.sigmoid(self.linear3(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandWritten(object):\n",
    "    def __init__(self,training_image,training_lable,eta,batch_size,shuffle,CEL): #CEL 代表使用交叉熵计算loss\n",
    "        self.CEL = CEL\n",
    "        self.dataset = HandWrittenDataset(training_image,training_lable,CEL = self.CEL)\n",
    "        number = len(training_image)\n",
    "        self.split_9_1(number,batch_size) #把数据分为训练集和测试集  详细过程见下面的那个split函数\n",
    "        self.dataloader = tud.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "        self.model = Net().cuda()  #定义模型类\n",
    "        if (CEL == True):\n",
    "            self.loss_fn = torch.nn.CrossEntropyLoss(reduction = 'sum') #定义loss_fn，loss方程\n",
    "        else:\n",
    "            self.loss_fn = torch.nn.MSELoss(reduction = 'sum') #定义loss_fn，loss方程\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = eta)#定义参数更新方式\n",
    "    def train(self): #开始训练\n",
    "        for e in range(NUM_EPOCHS): #每一个epochs\n",
    "            for i,(x,y) in enumerate (self.train_loader): #从dataloader中取出bitch数据进行训练\n",
    "#                 a = x[0].reshape(28,28) #显示图片\n",
    "#                 fig = plt.figure()\n",
    "#                 plotwindow = fig.add_subplot(111)\n",
    "#                 plt.imshow(a , cmap='gray')\n",
    "#                 plt.show()\n",
    "#                 print(y[0])\n",
    "                y_pred = self.model.forward(x)  #前项传播\n",
    "                if self.CEL == True:\n",
    "                    self.loss = self.loss_fn(y_pred,y.long()) #计算loss\n",
    "                else:\n",
    "                    self.loss = self.loss_fn(y_pred,y) #计算loss\n",
    "#                 print(self.loss)\n",
    "                self.optimizer.zero_grad() #参数更新器重置为0\n",
    "                self.loss.backward()   # 反向传播\n",
    "                self.optimizer.step() #参数更新\n",
    "                \n",
    "            print(e,\":轮，loss = \",self.loss.item())\n",
    "            print(\"准确率为：\",self.test());\n",
    "    def test(self): #测试函数\n",
    "        total_correct = 0.0\n",
    "        for i, (x,y) in enumerate(self.test_loader):\n",
    "            y_pred = self.model.forward(x)  #前项传播\n",
    "            if self.CEL == True:  #对于不同loss方程的处理\n",
    "                correct = self.correct_count_CEL(y,y_pred)\n",
    "            else:\n",
    "                correct = self.correct_count_MSE(y,y_pred)\n",
    "\n",
    "            total_correct = total_correct+correct\n",
    "#             pdb.set_trace()\n",
    "        \n",
    "        return total_correct/self.test_number\n",
    "    def correct_count_MSE(self,y,y_pred): #MES正确预测数量函数\n",
    "        return sum(a[torch.argmax(b)] == 1 for a, b in zip(y,y_pred))\n",
    "    def correct_count_CEL(self,y,y_pred): #CrossEntropyLoss正确预测数量函数\n",
    "        return sum(a == torch.argmax(b) for a, b in zip(y,y_pred))\n",
    "    def split_9_1(self,n_train,batch_size):\n",
    "        split = n_train // 10   #整数除法，要把数据分成9:1的训练集和测试集\n",
    "        self.test_number = split  #测试集总数\n",
    "        indices = list(range(n_train))\n",
    "        train_sampler = tud.sampler.SubsetRandomSampler(indices[split:])  #设置采样器\n",
    "        test_sampler = tud.sampler.SubsetRandomSampler(indices[:split])\n",
    "        self.train_loader = tud.DataLoader(self.dataset, sampler=train_sampler,batch_size = batch_size, shuffle=False)#利用采样的方法进行提取\n",
    "        self.test_loader = tud.DataLoader(self.dataset, sampler=test_sampler, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 784])\n",
      "0 :轮，loss =  8.909785270690918\n",
      "准确率为： tensor(0.5920)\n",
      "1 :轮，loss =  9.366279602050781\n",
      "准确率为： tensor(0.7760)\n",
      "2 :轮，loss =  8.034472465515137\n",
      "准确率为： tensor(0.8320)\n",
      "3 :轮，loss =  7.547613143920898\n",
      "准确率为： tensor(0.8030)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-55c2c58b958a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mHandWrittennet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHandWritten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_lable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCEL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mHandWrittennet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-117-aeae724b18f9>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#                 print(self.loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#参数更新器重置为0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# 反向传播\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#参数进行更新\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_image = training_image[:10000]\n",
    "training_lable = training_lable[:10000]\n",
    "print(training_image.shape)\n",
    "NUM_EPOCHS = 30\n",
    "HandWrittennet = HandWritten(training_image,training_lable,eta = 0.001,batch_size = 5,shuffle = False,CEL = True)\n",
    "HandWrittennet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
